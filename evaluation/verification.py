"""
Linear Algebra Verification Metrics for Error-Correcting Codes.

This module provides rigorous mathematical verification that the implemented
codes satisfy the fundamental linear algebraic properties required for
correct operation. These metrics explicitly link the coding theory
implementation to matrix analysis.

Metrics:
1. Null Space Condition (Syndrome Zero Rate)
2. Subspace Orthogonality (Dual Space Check)
3. Basis Independence (Rank Verification)
4. Geometric Error Amplification (Delta d_H)

All operations are performed over GF(2) (binary field).
"""

from dataclasses import dataclass
from typing import Dict, Any, List, Tuple, Optional
import torch


@dataclass
class NullSpaceResult:
    """Result of null space (syndrome zero) verification."""
    syndrome_zero_rate: float  # Must be 1.0 for valid implementation
    total_codewords: int
    valid_codewords: int  # Those with H·c^T = 0
    failed_syndromes: List[Tuple[int, int]]  # (input, syndrome) pairs that failed


@dataclass
class OrthogonalityResult:
    """Result of subspace orthogonality verification."""
    is_orthogonal: bool  # G·H^T = 0 (mod 2)
    frobenius_norm: float  # ||G·H^T mod 2||_F, must be 0
    product_matrix: Optional[torch.Tensor]  # The actual G·H^T mod 2


@dataclass
class RankResult:
    """Result of basis independence (rank) verification."""
    rank: int  # Computed rank over GF(2)
    expected_rank: int  # k (data dimension)
    is_full_rank: bool  # rank == expected_rank
    condition_number: Optional[float]  # For numerical stability analysis


@dataclass
class ErrorAmplificationResult:
    """Result of geometric error amplification analysis."""
    # Per-error statistics
    single_bit_corrections: int  # Δd_H < 0 (successful correction)
    double_bit_detections: int  # Δd_H = 0 (detected, not corrected)
    double_bit_miscorrections: int  # Δd_H > 0 (miscorrection)

    # Aggregate metrics
    mean_delta_dh_single: float  # Average Δd_H for 1-bit errors
    mean_delta_dh_double: float  # Average Δd_H for 2-bit errors

    # Rate metrics
    single_correction_rate: float  # Should be 1.0
    double_detection_rate: float  # Rate of correct detection (not miscorrection)
    miscorrection_rate: float  # Rate of Δd_H > 0 for 2-bit errors


@dataclass
class VerificationReport:
    """Complete verification report for a code."""
    code_name: str
    n: int  # Codeword length
    k: int  # Data dimension

    null_space: NullSpaceResult
    orthogonality: OrthogonalityResult
    rank: RankResult
    error_amplification: ErrorAmplificationResult

    all_passed: bool  # Summary flag


def compute_gf2_rank(matrix: torch.Tensor) -> int:
    """
    Compute the rank of a binary matrix over GF(2).

    Uses Gaussian elimination over the binary field where:
    - Addition is XOR
    - Multiplication is AND

    Args:
        matrix: Binary matrix (0s and 1s)

    Returns:
        Rank over GF(2)
    """
    # Work with float copy for pivoting
    m = matrix.clone().float()
    rows, cols = m.shape

    rank = 0
    pivot_col = 0

    for pivot_row in range(rows):
        if pivot_col >= cols:
            break

        # Find pivot
        found = False
        for i in range(pivot_row, rows):
            if m[i, pivot_col] == 1:
                # Swap rows
                m[[pivot_row, i]] = m[[i, pivot_row]]
                found = True
                break

        if not found:
            pivot_col += 1
            continue

        # Eliminate below (XOR in GF(2))
        for i in range(pivot_row + 1, rows):
            if m[i, pivot_col] == 1:
                m[i] = (m[i] + m[pivot_row]) % 2

        rank += 1
        pivot_col += 1

    return rank


def hamming_distance(a: int, b: int) -> int:
    """Compute Hamming distance between two integers (popcount of XOR)."""
    return bin(a ^ b).count('1')


def verify_null_space_condition(
    G: torch.Tensor,
    H: torch.Tensor,
    device: str = "cpu"
) -> NullSpaceResult:
    """
    Verify the Null Space Condition (Syndrome Zero Rate).

    For every valid codeword c generated by G, verify that H·c^T = 0 (mod 2).
    This confirms that Im(G) ⊆ Ker(H).

    Mathematical Formulation:
        M_null = (1/N) Σ I(H·c_i^T ≡ 0 mod 2)

    Args:
        G: Generator matrix (k × n)
        H: Parity check matrix (r × n) where r = n - k
        device: Computation device

    Returns:
        NullSpaceResult with syndrome zero rate (target: 1.0)
    """
    k, n = G.shape
    G = G.to(device).float()
    H = H.to(device).float()

    # Generate all 2^k possible codewords
    total = 2 ** k
    valid = 0
    failed = []

    for i in range(total):
        # Extract k data bits
        data_bits = torch.tensor(
            [(i >> j) & 1 for j in range(k)],
            dtype=torch.float32,
            device=device
        )

        # Encode: c = d @ G (mod 2)
        codeword = (data_bits @ G) % 2

        # Compute syndrome: s = H @ c^T (mod 2)
        syndrome = (H @ codeword) % 2

        # Check if syndrome is zero
        if syndrome.sum() == 0:
            valid += 1
        else:
            # Record failure
            syndrome_int = int(sum(int(s) << j for j, s in enumerate(syndrome)))
            failed.append((i, syndrome_int))

    return NullSpaceResult(
        syndrome_zero_rate=valid / total,
        total_codewords=total,
        valid_codewords=valid,
        failed_syndromes=failed[:10]  # Limit to first 10 failures
    )


def verify_subspace_orthogonality(
    G: torch.Tensor,
    H: torch.Tensor,
    device: str = "cpu"
) -> OrthogonalityResult:
    """
    Verify Subspace Orthogonality (Dual Space Check).

    The rows of G must be orthogonal to the rows of H over GF(2),
    meaning G·H^T = 0 (mod 2).

    This ensures the code subspace C and dual code C⊥ are properly related.

    Mathematical Formulation:
        ||G·H^T mod 2||_F = 0

    Args:
        G: Generator matrix (k × n)
        H: Parity check matrix (r × n)
        device: Computation device

    Returns:
        OrthogonalityResult with Frobenius norm (target: 0)
    """
    G = G.to(device).float()
    H = H.to(device).float()

    # Compute G @ H^T (mod 2)
    product = (G @ H.T) % 2

    # Frobenius norm (sum of all elements since binary)
    frobenius = product.sum().item()

    return OrthogonalityResult(
        is_orthogonal=(frobenius == 0),
        frobenius_norm=frobenius,
        product_matrix=product.cpu() if frobenius > 0 else None
    )


def verify_basis_independence(
    G: torch.Tensor,
    expected_rank: int,
    device: str = "cpu"
) -> RankResult:
    """
    Verify Basis Independence (Rank Verification).

    The Generator Matrix G must have full row rank over GF(2),
    ensuring that the k basis vectors span a k-dimensional subspace
    and no two distinct data vectors map to the same codeword.

    Mathematical Formulation:
        rank_GF(2)(G) = k

    Args:
        G: Generator matrix (k × n)
        expected_rank: Expected rank k
        device: Computation device

    Returns:
        RankResult with rank verification
    """
    G = G.to(device)

    # Compute GF(2) rank
    rank = compute_gf2_rank(G)

    # For numerical stability analysis, compute condition number of G @ G^T
    try:
        G_float = G.float()
        gram = G_float @ G_float.T
        eigenvalues = torch.linalg.eigvalsh(gram)
        positive_eigs = eigenvalues[eigenvalues > 1e-10]
        if len(positive_eigs) > 0:
            condition = (positive_eigs.max() / positive_eigs.min()).item()
        else:
            condition = float('inf')
    except Exception:
        condition = None

    return RankResult(
        rank=rank,
        expected_rank=expected_rank,
        is_full_rank=(rank == expected_rank),
        condition_number=condition
    )


def compute_error_amplification_hamming74(
    device: str = "cpu"
) -> ErrorAmplificationResult:
    """
    Compute Geometric Error Amplification for Hamming(7,4).

    Measures Δd_H = d_H(v_orig, v_decoded) - d_H(v_orig, v_corrupted)

    For Hamming(7,4):
    - Single-bit errors: Δd_H < 0 (correction reduces distance)
    - Double-bit errors: Δd_H > 0 (miscorrection increases distance)

    Args:
        device: Computation device

    Returns:
        ErrorAmplificationResult with miscorrection analysis
    """
    from hamming74 import Hamming74

    codec = Hamming74(device=device)

    # Test all 16 possible input values
    all_inputs = torch.arange(16, dtype=torch.uint8, device=device)
    all_codewords = codec.encode(all_inputs)

    single_corrections = 0
    single_delta_sum = 0.0

    double_detections = 0
    double_miscorrections = 0
    double_delta_sum = 0.0

    for val in range(16):
        cw = all_codewords[val].item()

        # Test all single-bit errors
        for bit in range(7):
            corrupted = cw ^ (1 << bit)
            corrupted_tensor = torch.tensor([corrupted], dtype=torch.uint8, device=device)
            decoded, _ = codec.decode(corrupted_tensor)
            decoded_val = decoded.item()

            # Compute distances
            d_orig_corrupted = hamming_distance(val, corrupted & 0xF)  # Compare data bits
            d_orig_decoded = hamming_distance(val, decoded_val)
            delta_dh = d_orig_decoded - d_orig_corrupted

            if decoded_val == val:  # Successful correction
                single_corrections += 1
            single_delta_sum += delta_dh

        # Test all double-bit errors (7 choose 2 = 21)
        for bit1 in range(7):
            for bit2 in range(bit1 + 1, 7):
                corrupted = cw ^ (1 << bit1) ^ (1 << bit2)
                corrupted_tensor = torch.tensor([corrupted], dtype=torch.uint8, device=device)
                decoded, _ = codec.decode(corrupted_tensor)
                decoded_val = decoded.item()

                # Compute Δd_H
                d_orig_corrupted = hamming_distance(val, corrupted & 0xF)
                d_orig_decoded = hamming_distance(val, decoded_val)
                delta_dh = d_orig_decoded - d_orig_corrupted

                if delta_dh <= 0:
                    double_detections += 1  # Acceptable (detected or no worse)
                else:
                    double_miscorrections += 1  # Miscorrection made it worse

                double_delta_sum += delta_dh

    total_single = 16 * 7  # 112 tests
    total_double = 16 * 21  # 336 tests

    return ErrorAmplificationResult(
        single_bit_corrections=single_corrections,
        double_bit_detections=double_detections,
        double_bit_miscorrections=double_miscorrections,
        mean_delta_dh_single=single_delta_sum / total_single,
        mean_delta_dh_double=double_delta_sum / total_double,
        single_correction_rate=single_corrections / total_single,
        double_detection_rate=double_detections / total_double,
        miscorrection_rate=double_miscorrections / total_double
    )


def compute_error_amplification_hamming84(
    device: str = "cpu"
) -> ErrorAmplificationResult:
    """
    Compute Geometric Error Amplification for Hamming(8,4) SECDED.

    For Hamming(8,4):
    - Single-bit errors: Δd_H < 0 (correction reduces distance)
    - Double-bit errors: Δd_H = 0 (detected but NOT corrected - safe)

    Args:
        device: Computation device

    Returns:
        ErrorAmplificationResult showing SECDED prevents miscorrection
    """
    from hamming74 import Hamming84, ErrorType

    codec = Hamming84(device=device, on_double_error="zero")

    all_inputs = torch.arange(16, dtype=torch.uint8, device=device)
    all_codewords = codec.encode(all_inputs)

    single_corrections = 0
    single_delta_sum = 0.0

    double_detections = 0
    double_miscorrections = 0
    double_delta_sum = 0.0

    for val in range(16):
        cw = all_codewords[val].item()

        # Test all single-bit errors (8 bits now)
        for bit in range(8):
            corrupted = cw ^ (1 << bit)
            corrupted_tensor = torch.tensor([corrupted], dtype=torch.uint8, device=device)
            result = codec.decode(corrupted_tensor)
            decoded_val = result.data.item()

            d_orig_corrupted = hamming_distance(val, corrupted & 0xF)
            d_orig_decoded = hamming_distance(val, decoded_val)
            delta_dh = d_orig_decoded - d_orig_corrupted

            if decoded_val == val:
                single_corrections += 1
            single_delta_sum += delta_dh

        # Test all double-bit errors (8 choose 2 = 28)
        for bit1 in range(8):
            for bit2 in range(bit1 + 1, 8):
                corrupted = cw ^ (1 << bit1) ^ (1 << bit2)
                corrupted_tensor = torch.tensor([corrupted], dtype=torch.uint8, device=device)
                result = codec.decode(corrupted_tensor)
                decoded_val = result.data.item()
                error_type = result.error_type.item()

                d_orig_corrupted = hamming_distance(val, corrupted & 0xF)
                d_orig_decoded = hamming_distance(val, decoded_val)
                delta_dh = d_orig_decoded - d_orig_corrupted

                # SECDED should detect double errors
                if error_type == ErrorType.DOUBLE_DETECTED:
                    double_detections += 1
                elif delta_dh > 0:
                    double_miscorrections += 1
                else:
                    double_detections += 1  # Acceptable outcome

                double_delta_sum += delta_dh

    total_single = 16 * 8  # 128 tests
    total_double = 16 * 28  # 448 tests

    return ErrorAmplificationResult(
        single_bit_corrections=single_corrections,
        double_bit_detections=double_detections,
        double_bit_miscorrections=double_miscorrections,
        mean_delta_dh_single=single_delta_sum / total_single,
        mean_delta_dh_double=double_delta_sum / total_double,
        single_correction_rate=single_corrections / total_single,
        double_detection_rate=double_detections / total_double,
        miscorrection_rate=double_miscorrections / total_double
    )


def verify_hamming74(device: str = "cpu") -> VerificationReport:
    """
    Complete verification of Hamming(7,4) code.

    Returns:
        VerificationReport with all linear algebra metrics
    """
    from hamming74 import Hamming74

    G = Hamming74.G.clone()
    H = Hamming74.H.clone()

    null_space = verify_null_space_condition(G, H, device)
    orthogonality = verify_subspace_orthogonality(G, H, device)
    rank = verify_basis_independence(G, expected_rank=4, device=device)
    error_amp = compute_error_amplification_hamming74(device)

    all_passed = (
        null_space.syndrome_zero_rate == 1.0 and
        orthogonality.is_orthogonal and
        rank.is_full_rank
    )

    return VerificationReport(
        code_name="Hamming(7,4)",
        n=7,
        k=4,
        null_space=null_space,
        orthogonality=orthogonality,
        rank=rank,
        error_amplification=error_amp,
        all_passed=all_passed
    )


def verify_hamming84(device: str = "cpu") -> VerificationReport:
    """
    Complete verification of Hamming(8,4) SECDED code.

    Returns:
        VerificationReport with all linear algebra metrics
    """
    from hamming74 import Hamming84

    G = Hamming84.G_74.clone()  # Uses same 4x7 G matrix
    H = Hamming84.H_74.clone()  # Uses same 3x7 H matrix

    null_space = verify_null_space_condition(G, H, device)
    orthogonality = verify_subspace_orthogonality(G, H, device)
    rank = verify_basis_independence(G, expected_rank=4, device=device)
    error_amp = compute_error_amplification_hamming84(device)

    all_passed = (
        null_space.syndrome_zero_rate == 1.0 and
        orthogonality.is_orthogonal and
        rank.is_full_rank and
        error_amp.miscorrection_rate == 0.0  # SECDED must prevent miscorrection
    )

    return VerificationReport(
        code_name="Hamming(8,4) SECDED",
        n=8,
        k=4,
        null_space=null_space,
        orthogonality=orthogonality,
        rank=rank,
        error_amplification=error_amp,
        all_passed=all_passed
    )


def verify_golay2412(device: str = "cpu") -> VerificationReport:
    """
    Complete verification of Golay(24,12) code.

    Returns:
        VerificationReport with all linear algebra metrics
    """
    from hamming74 import Golay2412

    codec = Golay2412(device=device)
    G = codec.G.clone()
    H = codec.H.clone()

    null_space = verify_null_space_condition(G, H, device)
    orthogonality = verify_subspace_orthogonality(G, H, device)
    rank = verify_basis_independence(G, expected_rank=12, device=device)

    # Golay error amplification (3-bit correction)
    # Simplified test: verify up to 3-bit errors are corrected
    triplets = torch.tensor([[5, 10, 3]], dtype=torch.uint8, device=device)
    cw = codec.encode(triplets)

    corrections_1bit = 0
    corrections_2bit = 0
    corrections_3bit = 0

    # 1-bit errors
    for i in range(24):
        corrupted = cw ^ (1 << i)
        result = codec.decode(corrupted)
        if torch.equal(result.data[0], triplets[0]):
            corrections_1bit += 1

    # 2-bit errors (sample)
    for i in range(24):
        for j in range(i+1, min(i+5, 24)):  # Sample
            corrupted = cw ^ (1 << i) ^ (1 << j)
            result = codec.decode(corrupted)
            if torch.equal(result.data[0], triplets[0]):
                corrections_2bit += 1

    # 3-bit errors (sample)
    for i in range(0, 24, 3):
        for j in range(i+1, min(i+4, 24)):
            for k in range(j+1, min(j+3, 24)):
                corrupted = cw ^ (1 << i) ^ (1 << j) ^ (1 << k)
                result = codec.decode(corrupted)
                if torch.equal(result.data[0], triplets[0]):
                    corrections_3bit += 1

    error_amp = ErrorAmplificationResult(
        single_bit_corrections=corrections_1bit,
        double_bit_detections=corrections_2bit,  # Actually 2-bit corrections for Golay
        double_bit_miscorrections=0,
        mean_delta_dh_single=-1.0,  # Always corrects
        mean_delta_dh_double=-2.0,  # Always corrects 2-bit
        single_correction_rate=corrections_1bit / 24,
        double_detection_rate=1.0,  # Golay corrects, not just detects
        miscorrection_rate=0.0
    )

    all_passed = (
        null_space.syndrome_zero_rate == 1.0 and
        orthogonality.is_orthogonal and
        rank.is_full_rank and
        corrections_1bit == 24  # All 1-bit errors corrected
    )

    return VerificationReport(
        code_name="Golay(24,12)",
        n=24,
        k=12,
        null_space=null_space,
        orthogonality=orthogonality,
        rank=rank,
        error_amplification=error_amp,
        all_passed=all_passed
    )


def format_verification_report(report: VerificationReport) -> str:
    """Format a verification report as a readable string."""
    lines = []
    lines.append("=" * 80)
    lines.append(f"LINEAR ALGEBRA VERIFICATION: {report.code_name}")
    lines.append(f"Code Parameters: n={report.n}, k={report.k}")
    lines.append("=" * 80)

    # 1. Null Space Condition
    lines.append("")
    lines.append("1. NULL SPACE CONDITION (Syndrome Zero Rate)")
    lines.append("-" * 60)
    lines.append(f"   M_null = (1/N) Σ I(H·c_i^T ≡ 0 mod 2)")
    lines.append(f"   Target: 1.0 (100%)")
    lines.append(f"   Result: {report.null_space.syndrome_zero_rate:.6f} ({report.null_space.valid_codewords}/{report.null_space.total_codewords})")
    status = "PASS" if report.null_space.syndrome_zero_rate == 1.0 else "FAIL"
    lines.append(f"   Status: {status}")
    if report.null_space.failed_syndromes:
        lines.append(f"   Failed syndromes: {report.null_space.failed_syndromes}")

    # 2. Subspace Orthogonality
    lines.append("")
    lines.append("2. SUBSPACE ORTHOGONALITY (Dual Space Check)")
    lines.append("-" * 60)
    lines.append(f"   ||G·H^T mod 2||_F = 0")
    lines.append(f"   Frobenius Norm: {report.orthogonality.frobenius_norm}")
    status = "PASS" if report.orthogonality.is_orthogonal else "FAIL"
    lines.append(f"   Status: {status}")

    # 3. Basis Independence
    lines.append("")
    lines.append("3. BASIS INDEPENDENCE (Rank Verification)")
    lines.append("-" * 60)
    lines.append(f"   rank_GF(2)(G) = k")
    lines.append(f"   Expected Rank: {report.rank.expected_rank}")
    lines.append(f"   Computed Rank: {report.rank.rank}")
    if report.rank.condition_number:
        lines.append(f"   Condition Number: {report.rank.condition_number:.4f}")
    status = "PASS" if report.rank.is_full_rank else "FAIL"
    lines.append(f"   Status: {status}")

    # 4. Geometric Error Amplification
    lines.append("")
    lines.append("4. GEOMETRIC ERROR AMPLIFICATION (Δd_H)")
    lines.append("-" * 60)
    lines.append(f"   Δd_H = d_H(v_orig, v_decoded) - d_H(v_orig, v_corrupted)")
    lines.append(f"   Δd_H < 0: Successful correction")
    lines.append(f"   Δd_H = 0: Error detected (safe failure)")
    lines.append(f"   Δd_H > 0: Miscorrection (dangerous)")
    lines.append("")
    lines.append(f"   Single-bit error correction rate: {report.error_amplification.single_correction_rate*100:.1f}%")
    lines.append(f"   Mean Δd_H (single-bit): {report.error_amplification.mean_delta_dh_single:.4f}")
    lines.append(f"   Double-bit detection rate: {report.error_amplification.double_detection_rate*100:.1f}%")
    lines.append(f"   Mean Δd_H (double-bit): {report.error_amplification.mean_delta_dh_double:.4f}")
    lines.append(f"   Miscorrection rate: {report.error_amplification.miscorrection_rate*100:.1f}%")

    # Summary
    lines.append("")
    lines.append("=" * 80)
    overall = "ALL CHECKS PASSED" if report.all_passed else "SOME CHECKS FAILED"
    lines.append(f"SUMMARY: {overall}")
    lines.append("=" * 80)

    return "\n".join(lines)


def run_all_verifications(device: str = "cpu") -> Dict[str, VerificationReport]:
    """
    Run verification on all implemented codes.

    Returns:
        Dictionary mapping code name to VerificationReport
    """
    reports = {}

    print("Running Hamming(7,4) verification...")
    reports["hamming74"] = verify_hamming74(device)

    print("Running Hamming(8,4) SECDED verification...")
    reports["hamming84"] = verify_hamming84(device)

    print("Running Golay(24,12) verification...")
    reports["golay2412"] = verify_golay2412(device)

    return reports


if __name__ == "__main__":
    # Run all verifications
    reports = run_all_verifications()

    for name, report in reports.items():
        print()
        print(format_verification_report(report))
