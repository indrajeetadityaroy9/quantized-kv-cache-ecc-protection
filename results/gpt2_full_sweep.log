2026-01-12 22:38:57.098636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-12 22:38:57.112830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1768257537.129949   21312 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1768257537.135487   21312 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1768257537.149134   21312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768257537.149157   21312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768257537.149161   21312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768257537.149163   21312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-12 22:38:57.152967: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'evaluation.experiments.monte_carlo' found in sys.modules after import of package 'evaluation.experiments', but prior to execution of 'evaluation.experiments.monte_carlo'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
`torch_dtype` is deprecated! Use `dtype` instead!
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
Loading model: gpt2
Monte Carlo BER Sweep
============================================================
Model: gpt2
Cache modes: ['int4', 'int4-hamming84', 'int4-hamming84-interp']
BER levels: [0.0, 0.0001, 0.001, 0.01]
Seeds: [42, 101, 997] (3 trials/config)
Samples: 3
KL Divergence: enabled
Top-5 Accuracy: enabled
Catastrophic Rate: enabled

Generating clean baseline logits for KL divergence...
  Generated 3 clean logits

  [  0.0%] int4 @ BER=0e+00 seed=42
  [  2.8%] int4 @ BER=0e+00 seed=101
  [  5.6%] int4 @ BER=0e+00 seed=997
  [  8.3%] int4 @ BER=1e-04 seed=42
  [ 11.1%] int4 @ BER=1e-04 seed=101
  [ 13.9%] int4 @ BER=1e-04 seed=997
  [ 16.7%] int4 @ BER=1e-03 seed=42
  [ 19.4%] int4 @ BER=1e-03 seed=101
  [ 22.2%] int4 @ BER=1e-03 seed=997
  [ 25.0%] int4 @ BER=1e-02 seed=42
  [ 27.8%] int4 @ BER=1e-02 seed=101
  [ 30.6%] int4 @ BER=1e-02 seed=997
  [ 33.3%] int4-hamming84 @ BER=0e+00 seed=42
  [ 36.1%] int4-hamming84 @ BER=0e+00 seed=101
  [ 38.9%] int4-hamming84 @ BER=0e+00 seed=997
  [ 41.7%] int4-hamming84 @ BER=1e-04 seed=42
  [ 44.4%] int4-hamming84 @ BER=1e-04 seed=101
  [ 47.2%] int4-hamming84 @ BER=1e-04 seed=997
  [ 50.0%] int4-hamming84 @ BER=1e-03 seed=42
  [ 52.8%] int4-hamming84 @ BER=1e-03 seed=101
  [ 55.6%] int4-hamming84 @ BER=1e-03 seed=997
  [ 58.3%] int4-hamming84 @ BER=1e-02 seed=42
  [ 61.1%] int4-hamming84 @ BER=1e-02 seed=101
  [ 63.9%] int4-hamming84 @ BER=1e-02 seed=997
  [ 66.7%] int4-hamming84-interp @ BER=0e+00 seed=42
  [ 69.4%] int4-hamming84-interp @ BER=0e+00 seed=101
  [ 72.2%] int4-hamming84-interp @ BER=0e+00 seed=997
  [ 75.0%] int4-hamming84-interp @ BER=1e-04 seed=42
  [ 77.8%] int4-hamming84-interp @ BER=1e-04 seed=101
  [ 80.6%] int4-hamming84-interp @ BER=1e-04 seed=997
  [ 83.3%] int4-hamming84-interp @ BER=1e-03 seed=42
  [ 86.1%] int4-hamming84-interp @ BER=1e-03 seed=101
  [ 88.9%] int4-hamming84-interp @ BER=1e-03 seed=997
  [ 91.7%] int4-hamming84-interp @ BER=1e-02 seed=42
  [ 94.4%] int4-hamming84-interp @ BER=1e-02 seed=101
  [ 97.2%] int4-hamming84-interp @ BER=1e-02 seed=997

Sweep complete!

Results saved to:
  - results/gpt2_full_sweep/monte_carlo_results.json
  - results/gpt2_full_sweep/results_table.txt
  - results/gpt2_full_sweep/results_table.tex

PERPLEXITY (lower is better)
--------------------------------------------------------------------------------
BER   | INT4 (Unprotected) | Hamming(8,4) | H(8,4)+Interp
---------------------------------------------------------
0     | 1.77               | 1.77         | 1.77         
1e-04 | 1.77+/-0.02        | 1.77         | 1.77         
1e-03 | 1.88+/-0.03        | 1.77+/-0.01  | 1.77+/-0.01  
1e-02 | 7.72+/-1.32        | 2.14+/-0.11  | 1.81         

KL DIVERGENCE (nats, lower is better - 0 = identical to clean)
--------------------------------------------------------------------------------
BER   | INT4 (Unprotected) | Hamming(8,4)    | H(8,4)+Interp  
--------------------------------------------------------------
0     | 0.0166             | 0.0166          | 0.0166         
1e-04 | 0.0208+/-0.0010    | 0.0166          | 0.0166         
1e-03 | 0.0752+/-0.0246    | 0.0187+/-0.0035 | 0.0156+/-0.0007
1e-02 | 1.5249+/-0.0720    | 0.3127+/-0.0371 | 0.0564+/-0.0109

TOP-5 ACCURACY % (higher is better - 100% = target always in top 5)
--------------------------------------------------------------------------------
BER   | INT4 (Unprotected) | Hamming(8,4) | H(8,4)+Interp
---------------------------------------------------------
0     | 93.9%              | 93.9%        | 93.9%        
1e-04 | 94.0+/-0.1%        | 93.9%        | 93.9%        
1e-03 | 93.9+/-0.4%        | 93.7+/-0.1%  | 93.7+/-0.1%  
1e-02 | 84.0+/-2.7%        | 93.1+/-1.2%  | 94.1+/-0.1%  

ERROR CORRECTION STATISTICS
--------------------------------------------------------------------------------
BER   | INT4 (Unprotected) | Hamming(8,4)       | H(8,4)+Interp     
--------------------------------------------------------------------
0     | -                  | -                  | -                 
1e-04 | -                  | 19,098 / 10        | 19,098 / 10       
1e-03 | -                  | 191,009 / 826      | 191,009 / 826     
1e-02 | -                  | 1,787,019 / 71,835 | 1,787,019 / 71,835

Note: Format is 'corrected / detected' for SECDED modes
